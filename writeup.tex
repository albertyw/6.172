\title{6.172 Project 1 Writeup}
\author{
    Albert Wang, Lekha Kuhananthan
}
\date{\today}

\documentclass[12pt]{article}
\linespread{2}


\begin{document}
\maketitle
\section{2}
\subsection{2.1}
We found that the memory leak was caused by not freeing the variable "right", 
so therefore we added $mem_free(\&right);$ to sort.c in the merge function, at 
the end and before the premature return statement.  After this fix, valgrind 
reported no lost memory.  

\subsection{2.2}
The perf annotated output for merge and sort showed that most of the program's 
time was spent in merge.  Merge had the following output:
\begin{verbatim}
Merge:
Slowest in:
   17.12 /afs/csail.mit.edu/u/a/albertyw/project1/sort/sort.c:60
   16.79 /afs/csail.mit.edu/u/a/albertyw/project1/sort/sort.c:61
   13.90 /afs/csail.mit.edu/u/a/albertyw/project1/sort/sort.c:56
   13.79 /afs/csail.mit.edu/u/a/albertyw/project1/sort/sort.c:55
    5.51 /afs/csail.mit.edu/u/a/albertyw/project1/sort/sort.c:53
\end{verbatim}
This means that most of the slowdown in the program is caused by branching and 
array indexing in the for loop of the merge function.  

\subsection{2.3}
% Check numbers.  
For an input of (2000, 100), the total time for sort without inline is 0.393289411 seconds elapsed while 
sort with inline is 0.393188160 seconds.  This is a 0.03\% speedup.  
The inline keyword is supposed to make the code speed up because inline 
causes the compiler to put the assembly code for a function in the place of 
where it is called, instead of making the assembly code jump to a different 
section for the function.  This makes the compiled code slightly faster at the 
expense of using more memory.  

However, the compiler can't do this everywhere.  

Recursive functions can't do this because it would be impossible to place a 
function's code inside of itself.  Also, inline code from a different file 
usually won't be inlined by the compiler because of dependencies.  

\subsection{2.4}
The array indeces were changed to pointers, and for an input of (20000, 100), time reduced from 3.904939 seconds
to 3.840331 seconds, a 1.65\% speedup.

\subsection{2.5}
The original code had a perf stat output of 
\begin{verbatim}
    $ ./sort_p.64 10000000 10

    20277655203  branches                 #      0.000 M/sec
     1389280173  branch-misses            #      0.000 M/sec
    69447260155  cycles                   #      0.000 M/sec
    89566910390  instructions             #      1.290 IPC  

   26.059289767  seconds time elapsed
\end{verbatim}
which means that the branch-misses to branches rate is 0.068512861.  After 
modifying the code to remove the single if statement in the merge for loop 
using a bit hack, the new perf stat output was:
\begin{verbatim}
    $ ./sort_p.64 10000000 10
    16757356921  branches                 #      0.000 M/sec
      208113220  branch-misses            #      0.000 M/sec
    62785649902  cycles                   #      0.000 M/sec
   111701277873  instructions             #      1.779 IPC

   23.560124343  seconds time elapsed
\end{verbatim}
The new branch-misses to branches rate is 0.0124192151 and the program is 10\% 
faster. Removing the branch requires additional instructions to compute the minimum. 

\subsection{2.6}
Insertion sort is faster than merge sort for smaller inputs. Thus, one can perform a binary search through
several input sizes to find the optimal size when insertion sort is a faster sort algorithm than merge sort.
In our case, this transition is found at an input size of 100.

\subsection{2.7}
It is very easy to remove the {\tt malloc} calls for {\tt right}. Because of the way merge sort works, even if
all the elements in {\tt left} are smaller than the first element of {\tt right}, the elements of {\tt right}
will never get overwritten even if they are left in the original array.

A compiler cannot automatically make these optimizations. It cannot predict that the space used by {\tt right}
will never be overwritten.

\subsection{2.8}
For an input of (20000, 100), the performance improved from 1.705721 seconds to 1.474061 seconds, a 13.5\%
speedup.

\section{3}
The general idea of the new reversal method is that the bits in to be reversed
are directly accessed and then switched using a 

\end{document}
